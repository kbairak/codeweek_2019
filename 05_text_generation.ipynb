{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T22:59:53.818308Z",
     "start_time": "2019-10-17T22:59:53.816387Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T22:59:54.063532Z",
     "start_time": "2019-10-17T22:59:54.042702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_file = tf.keras.utils.get_file(\n",
    "    'shakespeare.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    ")\n",
    "with open(path_to_file) as f:\n",
    "    text = f.read()\n",
    "    print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T22:59:55.226283Z",
     "start_time": "2019-10-17T22:59:55.201141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 0), (' ', 1), ('!', 2), ('$', 3), ('&', 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char = sorted(set(text))\n",
    "char2idx = {c: i for i, c in enumerate(idx2char)}\n",
    "list(char2idx.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T22:59:55.662213Z",
     "start_time": "2019-10-17T22:59:55.593598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18, 47, 56, 57, 58, 1, 15, 47, 58, 47]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int = [char2idx[c] for c in text]\n",
    "text_as_int[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T22:59:58.649843Z",
     "start_time": "2019-10-17T22:59:56.102198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function <lambda> at 0x7f75831c3a70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n",
      "WARNING: Entity <function <lambda> at 0x7f75831c3a70> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=36, shape=(64, 100), dtype=int32, numpy=\n",
       " array([[53, 44,  1, ...,  1, 50, 39],\n",
       "        [58, 46,  1, ...,  5, 42,  6],\n",
       "        [41, 49,  6, ...,  1, 30, 21],\n",
       "        ...,\n",
       "        [12,  0,  0, ..., 58, 53, 56],\n",
       "        [56, 50, 39, ..., 53,  1, 54],\n",
       "        [34, 27, 24, ..., 59, 57,  1]], dtype=int32)>,\n",
       " <tf.Tensor: id=37, shape=(64, 100), dtype=int32, numpy=\n",
       " array([[44,  1, 44, ..., 50, 39, 64],\n",
       "        [46,  1, 49, ..., 42,  6,  0],\n",
       "        [49,  6,  1, ..., 30, 21, 15],\n",
       "        ...,\n",
       "        [ 0,  0, 13, ..., 53, 56, 57],\n",
       "        [50, 39, 52, ...,  1, 54, 59],\n",
       "        [27, 24, 33, ..., 57,  1, 42]], dtype=int32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQUENCE_LENGTH, BATCH_SIZE, BUFFER_SIZE = 100, 64, 10_000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "dataset = dataset.batch(SEQUENCE_LENGTH + 1, drop_remainder=True)\n",
    "dataset = dataset.map(lambda s: (s[:-1], s[1:]))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "next(iter(dataset.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T22:59:58.926573Z",
     "start_time": "2019-10-17T22:59:58.651517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 8)             520       \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 512)           801792    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            33345     \n",
      "=================================================================\n",
      "Total params: 835,657\n",
      "Trainable params: 835,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "L = tf.keras.layers\n",
    "EMBEDDING_SIZE = 8\n",
    "RNN_SIZE = 512\n",
    "def get_model(batch_size=BATCH_SIZE):\n",
    "    return tf.keras.Sequential([\n",
    "        L.Embedding(len(idx2char), EMBEDDING_SIZE,\n",
    "                    batch_input_shape=(batch_size, None, )),\n",
    "        L.GRU(RNN_SIZE, return_sequences=True, stateful=True),\n",
    "        L.Dense(len(idx2char)),\n",
    "    ])\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T23:00:19.116811Z",
     "start_time": "2019-10-17T23:00:18.404552Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' cousin,\\nWhom it concerns to hear this matter forth,\\nDo with your injuries as seems you best,\\nIn any',\n",
       " 'Vhultng\\nAhi  In iomtest  th tirr thes canter trr h \\nAo tith tour snnuryes an toe s aou au t \\nA  t y ')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(dataset.take(1)))\n",
    "predictions = model(batch)\n",
    "predictions = tf.argmax(predictions, -1)\n",
    "predictions = predictions[0]\n",
    "sentence = \"\".join((idx2char[c.numpy()] for c in batch[0][0]))\n",
    "prediction = \"\".join((idx2char[c.numpy()] for c in predictions))\n",
    "sentence, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T23:00:24.672934Z",
     "start_time": "2019-10-17T23:00:24.665217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2410, shape=(), dtype=float32, numpy=1.113156>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "true = tf.reshape([1], (1, ))\n",
    "pred = tf.reshape([.8, .1, -3.4], (1, 3))\n",
    "loss_func(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T23:28:51.864946Z",
     "start_time": "2019-10-17T23:00:56.272366Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f74b8562170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x7f74b8562170> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.4963 - sparse_categorical_accuracy: 0.5556\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.4656 - sparse_categorical_accuracy: 0.5639\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4389 - sparse_categorical_accuracy: 0.5702\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.4172 - sparse_categorical_accuracy: 0.5757\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3959 - sparse_categorical_accuracy: 0.5813\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3769 - sparse_categorical_accuracy: 0.5865\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3603 - sparse_categorical_accuracy: 0.5906\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.3439 - sparse_categorical_accuracy: 0.5954\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.3278 - sparse_categorical_accuracy: 0.5994\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.3132 - sparse_categorical_accuracy: 0.6032\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.2991 - sparse_categorical_accuracy: 0.6072\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.2873 - sparse_categorical_accuracy: 0.6105\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.2739 - sparse_categorical_accuracy: 0.6140\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.2612 - sparse_categorical_accuracy: 0.6176\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.2489 - sparse_categorical_accuracy: 0.6214\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.2380 - sparse_categorical_accuracy: 0.6245\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.2265 - sparse_categorical_accuracy: 0.6281\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.2141 - sparse_categorical_accuracy: 0.6318\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.2035 - sparse_categorical_accuracy: 0.6345\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1926 - sparse_categorical_accuracy: 0.6384\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1819 - sparse_categorical_accuracy: 0.6414\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1715 - sparse_categorical_accuracy: 0.6448\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1604 - sparse_categorical_accuracy: 0.6481\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1508 - sparse_categorical_accuracy: 0.6513\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.1411 - sparse_categorical_accuracy: 0.6542\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1319 - sparse_categorical_accuracy: 0.6577\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1228 - sparse_categorical_accuracy: 0.6607\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1134 - sparse_categorical_accuracy: 0.6632\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.1058 - sparse_categorical_accuracy: 0.6663\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0975 - sparse_categorical_accuracy: 0.6688\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0894 - sparse_categorical_accuracy: 0.6717\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0819 - sparse_categorical_accuracy: 0.6746\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0748 - sparse_categorical_accuracy: 0.6766\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0671 - sparse_categorical_accuracy: 0.6795\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0607 - sparse_categorical_accuracy: 0.6816\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0545 - sparse_categorical_accuracy: 0.6840\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0471 - sparse_categorical_accuracy: 0.6862\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0425 - sparse_categorical_accuracy: 0.6880\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0362 - sparse_categorical_accuracy: 0.6899\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0314 - sparse_categorical_accuracy: 0.6917\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0267 - sparse_categorical_accuracy: 0.6932\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0221 - sparse_categorical_accuracy: 0.6948\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0175 - sparse_categorical_accuracy: 0.6965\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0150 - sparse_categorical_accuracy: 0.6972\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0095 - sparse_categorical_accuracy: 0.6993\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0056 - sparse_categorical_accuracy: 0.7006\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.0011 - sparse_categorical_accuracy: 0.7023\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9979 - sparse_categorical_accuracy: 0.7034\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9963 - sparse_categorical_accuracy: 0.7040\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9925 - sparse_categorical_accuracy: 0.7055\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9897 - sparse_categorical_accuracy: 0.7063\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9873 - sparse_categorical_accuracy: 0.7074\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9837 - sparse_categorical_accuracy: 0.7078\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9818 - sparse_categorical_accuracy: 0.7095\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9778 - sparse_categorical_accuracy: 0.7103\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9773 - sparse_categorical_accuracy: 0.7106\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9744 - sparse_categorical_accuracy: 0.7117\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9724 - sparse_categorical_accuracy: 0.7124\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 0.9700 - sparse_categorical_accuracy: 0.7130\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9689 - sparse_categorical_accuracy: 0.7136\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 17s 99ms/step - loss: 0.9674 - sparse_categorical_accuracy: 0.7141\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 0.9634 - sparse_categorical_accuracy: 0.7153\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 0.9625 - sparse_categorical_accuracy: 0.7161\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9621 - sparse_categorical_accuracy: 0.7160\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 0.9614 - sparse_categorical_accuracy: 0.7163\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9564 - sparse_categorical_accuracy: 0.7176\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9565 - sparse_categorical_accuracy: 0.7173\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 0.9549 - sparse_categorical_accuracy: 0.7181\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9536 - sparse_categorical_accuracy: 0.7185\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9514 - sparse_categorical_accuracy: 0.7193\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9494 - sparse_categorical_accuracy: 0.7202\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9502 - sparse_categorical_accuracy: 0.7202\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9484 - sparse_categorical_accuracy: 0.7203\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9470 - sparse_categorical_accuracy: 0.7211\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9467 - sparse_categorical_accuracy: 0.7212\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9444 - sparse_categorical_accuracy: 0.7219\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9419 - sparse_categorical_accuracy: 0.7231\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 0.9415 - sparse_categorical_accuracy: 0.7228\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9419 - sparse_categorical_accuracy: 0.7225\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9402 - sparse_categorical_accuracy: 0.7231\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9394 - sparse_categorical_accuracy: 0.7236\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9378 - sparse_categorical_accuracy: 0.7243\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9378 - sparse_categorical_accuracy: 0.7243\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9367 - sparse_categorical_accuracy: 0.7248\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9354 - sparse_categorical_accuracy: 0.7252\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9345 - sparse_categorical_accuracy: 0.7256\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9334 - sparse_categorical_accuracy: 0.7255\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9328 - sparse_categorical_accuracy: 0.7259\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9324 - sparse_categorical_accuracy: 0.7265\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9311 - sparse_categorical_accuracy: 0.7267\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9302 - sparse_categorical_accuracy: 0.7271\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9292 - sparse_categorical_accuracy: 0.7270\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9296 - sparse_categorical_accuracy: 0.7270\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 0.9279 - sparse_categorical_accuracy: 0.7276\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9275 - sparse_categorical_accuracy: 0.7272\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9284 - sparse_categorical_accuracy: 0.7275\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9254 - sparse_categorical_accuracy: 0.7282\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9242 - sparse_categorical_accuracy: 0.7289\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9244 - sparse_categorical_accuracy: 0.7285\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 0.9248 - sparse_categorical_accuracy: 0.7282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7583011790>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss_func,\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "model.fit(dataset, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T06:34:15.497136Z",
     "start_time": "2019-10-18T06:34:15.466506Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model('text_generation_backup.h5')\n",
    "# model.save('text_generation_backup.h5')\n",
    "# model.load_weights('text_generation.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T23:28:52.872441Z",
     "start_time": "2019-10-17T23:28:51.866358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 8)              520       \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 512)            801792    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             33345     \n",
      "=================================================================\n",
      "Total params: 835,657\n",
      "Trainable params: 835,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"unce it faithfully:\\nOr if thou think'st I am too quickly won,\\nI'll frown and be perverse an say thee\",\n",
       " \"ndh:In ioirh,ul y:\\niu if hhou think'st t am io  fuickly won,\\nI'll foiwn and seaaersereedon ahy thee \")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('text_generation.h5')\n",
    "model = get_model(1)\n",
    "model.load_weights('text_generation.h5')\n",
    "model.summary()\n",
    "batch = next(iter(dataset.take(1)))\n",
    "sentence = batch[0][:1]\n",
    "predictions = model(sentence)\n",
    "predictions = tf.argmax(predictions, -1)\n",
    "sentence = \"\".join((idx2char[i] for i in sentence[0]))\n",
    "predictions = \"\".join((idx2char[i] for i in predictions[0]))\n",
    "sentence, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T06:33:29.399995Z",
     "start_time": "2019-10-18T06:33:26.219580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: there 'tis here?\n",
      "I pray thee, more than length.\n",
      "\n",
      "Servented:\n",
      "I lay an old report and one that word\n",
      "'Twixt you there, and that the gods pale,\n",
      "The precious Plouding one another second bears,\n",
      "And make me stay with him and left them both.\n",
      "\n",
      "BAPTISTA:\n",
      "I have forgot you to your grace:\n",
      "I hope the crown beloved:\n",
      "Let him not think there's a fearful house.\n",
      "\n",
      "KING HENRY VI:\n",
      "Hark you, sir, the greater side in him adversaries\n",
      "Persuadest make me to the good worse.\n",
      "\n",
      "GLOUCESTER:\n",
      "I shall entreat your knowledge with\n",
      "statue of your daughter's earth arive away,\n",
      "That thou canst nothing but my heart to see,\n",
      "Who good be recond to the people.\n",
      "\n",
      "COMINIUS:\n",
      "He's sentenced here the chase of both,\n",
      "And save your father is changed into the king.\n",
      "\n",
      "DUKE OF AUMERLE:\n",
      "Unnew what I should sing it, in the new do me to be so but the ship of men\n",
      "The great complaining of thy love,\n",
      "Is not a metse princes. O that bear them\n",
      "Romoritable and friends no son of my imprisonment.\n",
      "\n",
      "GLOUCESTER:\n",
      "The first seven in the contrary doth of my lor\n"
     ]
    }
   ],
   "source": [
    "def generate(start_string=\"ROMEO: \", length=100, temperature=1.):\n",
    "    start = [char2idx[c] for c in start_string]\n",
    "    start = tf.reshape(start, (1, -1))\n",
    "    model.reset_states()\n",
    "    for _ in range(length):\n",
    "        prediction = model(start)\n",
    "        prediction = prediction[:, -1, :]\n",
    "        # prediction = tf.argmax(predictions, -1)\n",
    "        prediction = tf.random.categorical(prediction / temperature, 1)\n",
    "        start = tf.reshape(prediction, (1, 1))\n",
    "        start_string += idx2char[tf.reshape(prediction, ()).numpy()]\n",
    "    return start_string\n",
    "print(generate(length=1000, temperature=.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
